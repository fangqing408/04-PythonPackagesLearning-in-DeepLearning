dataset,save_dir,type_name,type_network,sampler,num_woekers,shuffle,pin_memory,drop_last,batch_size,embedding_size,cosine_scale,num_layers,topk,t_diff,use_ema,ema_m,learning_rate,learning_head,learning_rate_pga,weight_decay,weight_decay_pga,optimizer,scheduler,sgd_momentum,cosinelr_eta_min,steplr_step_size,steplr_gamma,lambda_K,lambda_Z,lambda_idea,lambda_phase,total_epochs,warmup_epochs_K,warmup_epochs_Z,input_shape,enhance,alpha,beta,sigma_in,sigma_out,val_acc,备注
MNIST,train_mnist_log,softmax_v1,MobileNet,default,4,TRUE,TRUE,TRUE,128,512,32,\,\,\,\,\,1e-5,1e-5,\,1e-5,\,AdamW,CosineAnnealingLR,\,1e-7,\,\,\,\,\,\,100,\,\,"1,128,128",FALSE,\,\,\,\,98.21%,\
MNIST,train_mnist_log,softmax_v2,MobileNet,default,4,TRUE,TRUE,TRUE,128,512,32,\,\,\,\,\,1e-5,1e-5,\,1e-5,\,AdamW,CosineAnnealingLR,\,1e-7,\,\,\,\,\,\,100,\,\,"1,128,128",FALSE,\,\,\,\,98.17%,\
MNIST,train_mnist_log,pga_v1,MobileNet,default,4,TRUE,TRUE,TRUE,128,512,32,5,8,1,TRUE,0.85-0.95,1e-5,1e-5,3e-6,1e-5,1e-5,AdamW,CosineAnnealingLR,\,1e-7,\,\,4.0-64.0,4.0-16.0,1,0.5-0.5,100,10,20,"1,128,128",FALSE,1.0-1.2,0,0.99,0,98.60%,\
MNIST,train_mnist_log,pga_v2,MobileNet,default,4,TRUE,TRUE,TRUE,128,512,32,5,8,1,TRUE,0.85-0.95,1e-5,1e-5,3e-6,1e-5,1e-5,AdamW,CosineAnnealingLR,\,1e-7,\,\,4.0-64.0-6.4,4.0-16.0-1.6,1,0.5-0.2-0.3,100,10,20,"1,128,128",FALSE,1.0-1.2,0,0.99,0,98.61%,\
MNIST,train_mnist_log,pga_v3,MobileNet,default,4,TRUE,TRUE,TRUE,128,512,32,5,8,1,TRUE,0.9,1e-5,1e-5,1e-6,1e-5,1e-5,AdamW,CosineAnnealingLR,\,1e-7,\,\,4.0-64.0,4.0-16.0,1,0.5-0.5,100,10,20,"1,128,128",FALSE,1.0-1.2,0,0.99,0,98.66%,\
MNIST,train_mnist_log,pga_v4,MobileNet,default,4,TRUE,TRUE,TRUE,128,512,32,5,8,1,TRUE,0.9,1e-5,1e-5,1e-6,1e-5,1e-5,AdamW,CosineAnnealingLR,\,1e-7,\,\,4.0-64.0,4.0-16.0,1,0.5-0.5,100,10,20,"1,128,128",FALSE,1.0-1.2,0,0.99,0,98.63%,\
MNIST,train_mnist_log,pga_v5,MobileNet,default,4,TRUE,TRUE,TRUE,128,512,32,5,8,1,TRUE,0.9,1e-5,1e-5,1e-6,1e-5,1e-5,AdamW,CosineAnnealingLR,\,1e-7,\,\,4.0-64.0,4.0-16.0,1,0.5-0.5,100,10,20,"1,128,128",FALSE,1.0-1.2,0,0.99,0,98.66%,\
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CASIA-WebFace,train_casia_log_100,softmax_v1,MobileNet,PKsampler:16*16,4,\,\,\,256,512,16,\,\,\,\,\,2e-5,6e-5,\,5e-4,\,AdamW,CosineAnnealingLR,\,2e-7,\,\,\,\,\,\,100,\,\,"3,128,128",p=0.5,\,\,\,\,75.00%,证明了 MobileNet 网络不行，还不确定 PK 采样的正确性
CASIA-WebFace,train_casia_log_30,softmax_v1,ResNet50,PKsampler:64*8,6,\,\,\,512,512,16,\,\,\,\,\,1e-3,3e-3,\,5e-4,\,SGD,CosineAnnealingLR,0.9,1e-5,\,\,\,\,\,\,30,\,\,"3,112,112",p=0.5&136-112randcut,\,\,\,\,94.08%,对比下面的实验，在同一条件下，全 PK 采样完全落后于随机采样，因为减少了很多的对比度
CASIA-WebFace,train_casia_log_30,softmax_v3,ResNet50,default,6,TRUE,TRUE,TRUE,512,512,16,\,\,\,\,\,1e-3,3e-3,\,5e-4,\,SGD,CosineAnnealingLR,0.9,1e-5,\,\,\,\,\,\,30,\,\,"3,112,112",p=0.5&136-112randcut,\,\,\,\,95.33%,与上面的实验做对比，其余实验条件完全相同
CASIA-WebFace,train_casia_log_30,pga_v1,ResNet50,PKsampler:64*8,6,\,\,\,512,512,16,10,6,1,TRUE,0.9,1e-3,3e-3,1e-4,5e-4,0,SGD,CosineAnnealingLR,0.9,1e-5,\,\,4.0-64.0,4.0-16.0,1,0.5-0.5,30,6,12,"3,112,112",p=0.5&136-112randcut,0.8-1.2,0,0.99,\,94.15%,
CASIA-WebFace,train_casia_log_30,pga_v2,ResNet50,PKsampler:64*8,6,\,\,\,512,512,16,10,6,1,TRUE,0.9,1e-3,3e-3,5e-4,5e-4,0,SGD+AdamW,CosineAnnealingLR,0.9,1e-5,\,\,4.0-64.0,4.0-16.0,1,0.5-0.5,30,4,8,"3,112,112",p=0.5&136-112randcut,1.0-1.5,0,0.99,\,94.43%,
CASIA-WebFace,train_casia_log_30,pga_v3,ResNet50,PKsampler:64*8,6,\,\,\,512,512,16,10,6,1,TRUE,0.8,1e-3,3e-3,5e-4,5e-4,0,SGD+AdamW,CosineAnnealingLR,0.9,2e-4,\,\,4.0-128.0,4.0-32.0,2,0.5-0.5,30,4,8,"3,112,112",p=0.5&136-112randcut,1.0-1.7,0,0.99,\,94.75%,
CASIA-WebFace,train_casia_log_30,pga_v4,ResNet50,PKsampler:64*8,6,\,\,\,512,512,16,10,6,1,TRUE,0.8,1e-3,3e-3,5e-4,5e-4,0,SGD+AdamW,CosineAnnealingLR,0.9,1e-5,\,\,0.0-16.0,0.0-8.0,1,0.5-0.5,30,4,8,"3,112,112",p=0.5&136-112randcut,1.0-1.7,0,0.99,\,94.77%,把除B^2改为了除以边数，pga损失变大了，发现了alpha 没任何作用，效果好更好的原因全是图对齐是现实的
CASIA-WebFace,train_casia_log_30,pga_arcface_v4,ResNet50,PKsampler:64*8,6,\,\,\,512,512,16,10,6,1,TRUE,0.8,1e-3,3e-3,5e-4,5e-4,0,SGD+AdamW,CosineAnnealingLR,0.9,1e-5,\,\,0.0-16.0,0.0-8.0,\,0.5-0.5,30,4,8,"3,112,112",p=0.5&136-112randcut,\,\,\,\,95.05%,m=0.5
