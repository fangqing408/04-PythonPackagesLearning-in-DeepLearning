{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19538124",
   "metadata": {},
   "source": [
    "tochvision 主要处理图像数据，包含一些常用的数据集、模型、转换函数等。torchvision独立于PyTorch，需要专门安装，torchvision主要包含以下四部分：\n",
    "\n",
    "torchvision.models: 提供深度学习中各种经典的网络结构、预训练好的模型，如：Alex-Net、VGG、ResNet、Inception等\n",
    "\n",
    "torchvision.datasets：提供常用的数据集，设计上继承 torch.utils.data.Dataset，主要包括：MNIST、CIFAR10/100、ImageNet、COCO等\n",
    "\n",
    "torchvision.transforms：提供常用的数据预处理操作，主要包括对Tensor及PIL Image对象的操作\n",
    "\n",
    "torchvision.utils：工具类，如保存张量作为图像到磁盘，给一个小批量创建一个图像网格\n",
    "\n",
    "torchvision要注意与pytorch版本和Cuda相匹配。要查询pytorch和torchvision的版本，可以使用下面语句："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9155ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n",
      "0.23.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d63751",
   "metadata": {},
   "source": [
    "(1) 加载几个预训练模型\n",
    "\n",
    "通过 pretrined=True 可以加载预训练模型。pretrained 默认值是 False，不赋值和赋值 False 效果一样\n",
    "\n",
    "选择了 pretrained 为 True 的话，点击运行会执行下载预训练参数的操作，不加载预训练模型没有这步操作，可以直接使用网络架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec025f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")>\n",
      "features.0.weight torch.Size([64, 3, 3, 3])\n",
      "features.0.bias torch.Size([64])\n",
      "features.2.weight torch.Size([64, 64, 3, 3])\n",
      "features.2.bias torch.Size([64])\n",
      "features.5.weight torch.Size([128, 64, 3, 3])\n",
      "features.5.bias torch.Size([128])\n",
      "features.7.weight torch.Size([128, 128, 3, 3])\n",
      "features.7.bias torch.Size([128])\n",
      "features.10.weight torch.Size([256, 128, 3, 3])\n",
      "features.10.bias torch.Size([256])\n",
      "features.12.weight torch.Size([256, 256, 3, 3])\n",
      "features.12.bias torch.Size([256])\n",
      "features.14.weight torch.Size([256, 256, 3, 3])\n",
      "features.14.bias torch.Size([256])\n",
      "features.17.weight torch.Size([512, 256, 3, 3])\n",
      "features.17.bias torch.Size([512])\n",
      "features.19.weight torch.Size([512, 512, 3, 3])\n",
      "features.19.bias torch.Size([512])\n",
      "features.21.weight torch.Size([512, 512, 3, 3])\n",
      "features.21.bias torch.Size([512])\n",
      "features.24.weight torch.Size([512, 512, 3, 3])\n",
      "features.24.bias torch.Size([512])\n",
      "features.26.weight torch.Size([512, 512, 3, 3])\n",
      "features.26.bias torch.Size([512])\n",
      "features.28.weight torch.Size([512, 512, 3, 3])\n",
      "features.28.bias torch.Size([512])\n",
      "classifier.0.weight torch.Size([4096, 25088])\n",
      "classifier.0.bias torch.Size([4096])\n",
      "classifier.3.weight torch.Size([4096, 4096])\n",
      "classifier.3.bias torch.Size([4096])\n",
      "classifier.6.weight torch.Size([1000, 4096])\n",
      "classifier.6.bias torch.Size([1000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [-1, 512, 14, 14]               0\n",
      "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.78\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 747.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "from torchsummary import summary as sumy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "resnet18 = models.resnet18(weights='IMAGENET1K_V1')\n",
    "vgg16 = models.vgg16(weights='IMAGENET1K_V1')\n",
    "alexnet = models.alexnet(weights='IMAGENET1K_V1')\n",
    "squeezenet = models.squeezenet1_0(weights='IMAGENET1K_V1')\n",
    "densenet = models.densenet161(weights='IMAGENET1K_V1')\n",
    "resnet152 = models.resnet152()\n",
    "# 可以使用该方法打印加载的预训练模型的参数\n",
    "for name, param in vgg16.named_parameters():\n",
    "    print(name, param.shape)\n",
    "vgg16 = vgg16.to(device)\n",
    "sumy(vgg16, input_size=(3, 224, 224), device=str(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e95fe",
   "metadata": {},
   "source": [
    "vgg16.state_dict() 前面方法得到模型的参数\n",
    "\n",
    "加载本地的模型参数使用方法 vgg16.load_state_dict()\n",
    "\n",
    "需要结合加载文件转化为字典的函数 torch.load_dict() 一起使用，也就是 vgg16.load_state_dict(torch.load_dict(xxxx.pth))\n",
    "\n",
    "保存模型的参数需要得到模型和的字典，然后使用 torch.save() 函数来保存，torch.save(vgg16.state_dict(), \"xxxx.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b35e645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_state_dict = vgg16.state_dict()\n",
    "resnet18_state_dict = resnet18.state_dict()\n",
    "\n",
    "torch.save(vgg16_state_dict, \"./vgg16_state_dict.pth\")\n",
    "torch.save(resnet18_state_dict, \"./resnet18_state_dict.pth\")\n",
    "\n",
    "vgg16.load_state_dict(torch.load(\"./vgg16_state_dict.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fea2eb",
   "metadata": {},
   "source": [
    "但是正常的使用过程中可能会修改模型的层数，想要接着使用预训练的参数就会出现无法加载的问题，所以必须在 pth 文件里面删掉或者加上相应的修改的层\n",
    "\n",
    "加入现在 resnet18 的分类任务变为了分类为 10 类，就需要对最后的全连接层进行修改\n",
    "\n",
    "层的名字和 shape 都是匹配的话，成功的加载，名字不匹配但是形状匹配的话，strict=False 会忽略错误，名字匹配但是形状不匹配，都会报错\n",
    "\n",
    "pretrained_dict = {k : v for k, v in pretrained_dict.items() if k in model_dict} 这个写法很显然只会比较键是不是完全一样，即使修改了形状也不会关心，所以需要加上判断，v.shape 和 model_dict[k].shape 要是一样的才行，这样的话，只会从预训练模型里面加载确定都没有修改的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af03667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([1000])\n",
      "Missing keys: ['fc.weight', 'fc.bias']\n",
      "Unexpected keys: []\n",
      "tensor(9.4485e-06, grad_fn=<MeanBackward0>) tensor(0.0254, grad_fn=<StdBackward0>)\n",
      "tensor(5.8502e-08, grad_fn=<MeanBackward0>) tensor(0.0695, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = models.resnet18(weights=None)\n",
    "\n",
    "model.fc = nn.Linear(512, 10)\n",
    "pretrained_dict = resnet18.state_dict()\n",
    "model_dict = model.state_dict()\n",
    "print(pretrained_dict.keys() == model_dict.keys())\n",
    "print(pretrained_dict['fc.bias'].size())\n",
    "pretrained_dict = {k : v for k, v in pretrained_dict.items() if k in model_dict and v.shape == model_dict[k].shape}\n",
    "# print(pretrained_dict['fc.bias']) 这句话会报错因为修改了全连接层，这个参数没有被加载\n",
    "# res = model.load_state_dict(torch.load('./resnet18_state_dict.pth'), strict=False) 报错，因为无法对应，原本的预训练模型的全连接层的大小为 [512, 1000]，现在被我修改为了 [512, 10]\n",
    "res = model.load_state_dict(pretrained_dict, strict=False) # 完美的加载，验证了自己的想法，现在删掉了全连接层的参数，其他的参数的预训练的参数了\n",
    "\n",
    "print(\"Missing keys:\", res.missing_keys) # 模型中存在，但是在预训练参数里面找不到\n",
    "print(\"Unexpected keys:\", res.unexpected_keys) # 预训练参数中存在模型中没定义，这个不会遇到，因为我强制的比对了键值对，模型中没定义的一定会被删掉的\n",
    "\n",
    "print(model.fc.weight.mean(), model.fc.weight.std())  # 随机分布\n",
    "print(resnet18.fc.weight.mean(), resnet18.fc.weight.std())  # 不同分布\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a32a2",
   "metadata": {},
   "source": [
    "上面简单的介绍了模型的加载和报错，和加载预训练参数的方法等，这个是 torchvision.models 库函数里面常见的操作了，总结下列函数：\n",
    "\n",
    "models.model() 加载名字为 model 的模型，一般的参数为 weights，代表加载预训练参数，不想加载的话初始化为 weights=None\n",
    "\n",
    "model.named_parameters() 返回键值对，代表层的名字和对应的 shape\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "202510-learning (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
