{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4132c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n",
      "True\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+trwt4W1TxfrcOl6VDvlc5eRvuRL3Zj2A/wD1V0Xj74YXvgeKG5S+TU7NmMU00MRUW8oCnY/JAzu455x0FcHVnTrC51XUrbT7OMyXNzKsUaDuxOBXrmveMYfhfpk/gfwsG/tCJ1e/1TOC8pwWVR2GMLnIxg9+aboGsX/jvwD8SLrX7tpXjitrqPaAio6iTGAOMHYo98eteOV0ngC8t7D4gaDd3cyQ28V5G0kjnCqM9SfSvRvFXwjgttb1LxDr/i6xs9Hup3uY5QpeaYMxbaqjAJwe2fpXDeJ/Fdk+nHw34Whez8PKweTzADNeSA/6yRuuPReAPT046iiiiv/Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABIUlEQVR4AWIYBMB4/t/5RjjcYfDuz58/b7FLmj3+++f9yz+WbJjSXDYP/vz9cyrkz98qiCQThAKTMw/IMDAwGPEcZNAF85Eljb0ZGQ+VMr44P4mJESKJACC3bObxrhRlYPj7Gc3Bakv/vrwQAlH7989SCAMK2Df9+eAuDLKTgYHh75/DUGEIsPzzxx7CwiJ57O8+uBzD/79HwByoV3wM/m8C88HEv/8XwDQUhP55JgllMrC3/93FA+OAQOif+yAKhNmb/zx0BzHgOPTPRCjbYOmftVAmjAIs7O9DCLPo3d9FEBaCDP3zc5KBbOimh3/vL7dACENYoX/+/Hl6/c+fP0eaIALIpMzxP3/+/vnzEmYzshwDg2TDn79/elVRBQeCBwCscG5E1y1scgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "img = Image.open('mnist_train_torch/0/00000.png')\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "723f5206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 128])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class Config:\n",
    "    backbone = 'resnet153' # [timm]\n",
    "    metric = 'arcface' # ['arcface', 'cosface]\n",
    "    embedding_size = 512\n",
    "    input_shape = [1, 128, 128]\n",
    "    train_transform = T.Compose([ \n",
    "        T.Grayscale(num_output_channels=1),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.Resize((144, 144)),\n",
    "        T.RandomCrop(input_shape[1:]),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.5], std=[0.5]) \n",
    "        # 需要注意的是，这个 mean 指的是均值减去 0.5 并不是把当前的像素点的均值变成 0.5，\n",
    "        # 也就是默认了现在的均值为 0.5，标准差为 0.5，转化为了均值为 0，标准差为 1 的一般形式\n",
    "    ])\n",
    "    test_transforme = T.Compose([\n",
    "        T.Grayscale(num_output_channels=1),\n",
    "        T.Resize(input_shape[1:]),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    train_root = \"./mnist_train_torch\"\n",
    "    test_root = \"./lfw-align-128\"\n",
    "    test_list = \"./lfw_test_pair.txt\"\n",
    "    checkpoints = \"checkpoints\"\n",
    "    test_model = \"checkpoints/0.pth\"\n",
    "    train_batch_size = 64\n",
    "    test_batch_size = 64\n",
    "    epochs = 10\n",
    "    optimizer = \"sgd\" # ['sgd', 'adam']\n",
    "    lr = 1e-1\n",
    "    lr_step = 10\n",
    "    lr_decay = 0.95\n",
    "    weight_decay = 5e-4\n",
    "    loss = \"focal_loss\" # ['focal_loss', 'cross_entropy']\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    pin_memory = True\n",
    "    num_workers = 4\n",
    "config = Config()\n",
    "\n",
    "# 展示经过 train_transform 转化之后的图片\n",
    "show_img = ((config.train_transform(img)) * 0.5 + 0.5).clamp(0, 1)\n",
    "print(show_img.shape)\n",
    "to_image = T.ToPILImage()\n",
    "display(to_image(show_img))\n",
    "\n",
    "display(config.train_transform(img))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a000329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "def load_data(conf, training = True):\n",
    "    if training:\n",
    "        data_root = conf.train_root\n",
    "        transform = conf.train_transform\n",
    "        batch_size = conf.train_batch_size\n",
    "    else:\n",
    "        data_root = conf.test_root\n",
    "        transform = conf.test_transform\n",
    "        batch_size = conf.test_batch_size\n",
    "    data = ImageFolder(data_root, transform=transform)\n",
    "    class_num = len(data.classes)\n",
    "    loader = DataLoader(data, batch_size=batch_size, shuffle=True, pin_memory=conf.pin_memory, num_workers=conf.num_workers)\n",
    "    return loader, class_num\n",
    "\n",
    "loader, class_num = load_data(config, True)\n",
    "\n",
    "print(class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b59cf91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "    \n",
    "class ConvBn(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=1, padding=0, groups=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel, stride, padding, groups=groups, bias=False),\n",
    "            nn.BatchNorm2d(out_c)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class ConvBnPrelu(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=1, padding=0, groups=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            ConvBn(in_c, out_c, kernel, stride, padding, groups),\n",
    "            nn.PReLU(out_c)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DepthWise(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel=(3, 3), stride=2, padding=0, groups=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            ConvBnPrelu(in_c, groups, kernel=(1, 1), stride=1, padding=0),\n",
    "            ConvBnPrelu(groups, groups, kernel=kernel, stride=stride, padding=padding, groups=groups),\n",
    "            ConvBn(groups, out_c, kernel=(1, 1), stride=1, padding=0)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DepthWiseRes(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel=(3, 3), stride=2, padding=2, groups=1):\n",
    "        super().__init__()\n",
    "        self.net = DepthWise(in_c, out_c, kernel, stride, padding, groups)\n",
    "    def forward(self, x):\n",
    "        return self.net(x) + x\n",
    "    \n",
    "class MultiDepthWiseRes(nn.Module):\n",
    "    def __init__(self, num_block, channels, kernel=(3, 3), stride=1, padding=1, groups=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(*[ # 解包把列表展开传给 Sequential\n",
    "            DepthWiseRes(channels, channels, kernel, stride, padding, groups)\n",
    "            for _ in range(num_block)\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "794148eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceMobileNet(nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBnPrelu(1, 64, kernel=(3, 3), stride=2, padding=1)\n",
    "        self.conv2 = ConvBn(64, 64, kernel=(3, 3), stride=1, padding=1, groups=64)\n",
    "        self.conv3 = DepthWise(64, 64, kernel=(3, 3), stride=2, padding=1, groups=128)\n",
    "        self.conv4 = MultiDepthWiseRes(num_block=4, channels=64, kernel=3, stride=1, padding=1, groups=128)\n",
    "        self.conv5 = DepthWise(64, 128, kernel=(3, 3), stride=2, padding=1, groups=256)\n",
    "        self.conv6 = MultiDepthWiseRes(num_block=6, channels=128, kernel=(3, 3), stride=1, padding=1, groups=256)\n",
    "        self.conv7 = DepthWise(128, 128, kernel=(3, 3), stride=2, padding=1, groups=512)\n",
    "        self.conv8 = MultiDepthWiseRes(num_block=2, channels=128, kernel=(3, 3), stride=1, padding=1, groups=256)\n",
    "        self.conv9 = ConvBnPrelu(128, 512, kernel=(1, 1))\n",
    "        self.conv10 = ConvBn(512, 512, groups=512, kernel=(7, 7))\n",
    "        self.flatten = Flatten()\n",
    "        self.linear = nn.Linear(2048, embedding_size, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(embedding_size)\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.conv6(out)\n",
    "        out = self.conv7(out)\n",
    "        out = self.conv8(out)\n",
    "        out = self.conv9(out)\n",
    "        out = self.conv10(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.bn(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa11e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.ce = torch.nn.CrossEntropyLoss()\n",
    "    def forward(self, input, target):\n",
    "        logp = self.ce(input, target)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = (1 - p) ** self.gamma * logp\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3d0588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class CosFace(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.40):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "    def forward(self, input, label):\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        phi = cosine - self.m\n",
    "        output = cosine * 1.0\n",
    "        batch_size = len(output)\n",
    "        output[range(batch_size), label] = phi[range(batch_size), label]\n",
    "        return output * self.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fd1677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|##########| 938/938 [02:17<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.5279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|##########| 938/938 [00:49<00:00, 18.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.2891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|##########| 938/938 [01:06<00:00, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.2029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|##########| 938/938 [01:55<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.1633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|##########| 938/938 [00:54<00:00, 17.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|##########| 938/938 [01:12<00:00, 13.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.1378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|##########| 938/938 [01:39<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|##########| 938/938 [00:52<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.1172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|##########| 938/938 [00:52<00:00, 17.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.1031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|##########| 938/938 [00:51<00:00, 18.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataloader, class_num = load_data(config, training=True)\n",
    "    device = config.device\n",
    "    embedding_size = config.embedding_size\n",
    "    net = FaceMobileNet(embedding_size).to(device)\n",
    "    metric = CosFace(embedding_size, class_num).to(device)\n",
    "    criterion = FocalLoss(gamma=2)\n",
    "    optimizer = optim.SGD(\n",
    "        list(net.parameters()) + list(metric.parameters()),\n",
    "        lr=config.lr,\n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config.lr_step, gamma=0.1)\n",
    "    net.train()\n",
    "    for e in range(config.epochs):\n",
    "        total_loss = 0\n",
    "        for data, labels in tqdm(dataloader, desc=f\"Epoch {e+1}/{config.epochs}\", ascii=True):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            embeddings = net(data)\n",
    "            thetas = metric(embeddings, labels)\n",
    "            loss = criterion(thetas, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {e+1}/{config.epochs}, Loss: {avg_loss:.4f}\")\n",
    "        torch.save(net.state_dict(), f\"checkpoint_epoch_{e+1}.pth\")\n",
    "        scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "202510-learning (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
