{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd96e4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,) 1\n",
      "(3, 3) 2\n",
      "(1, 3) 2\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3]) # torch 的转化张量的方法为 torch.tensor()，转化为 numpy 数组的方法为 numpy.array()\n",
    "print(a.shape, a.ndim)\n",
    "\n",
    "a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(a.shape, a.ndim)\n",
    "\n",
    "a = np.array([[1, 2, 3]])\n",
    "print(a.shape, a.ndim)\n",
    "\n",
    "print(len(a.shape) == a.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb5845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n",
      "30 int64\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]] float64\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "b = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(b.size, math.prod(b.shape))  # torch 没有 size 属性，其中的 size() 是方法，shape 返回的就是这个方法，二者完全等价，numel() 方法等价于 numpy 是 size 属性\n",
    "print(np.prod((1, 2, 3, 5)), b.dtype) # torch.prod() 方法只接受参数为 tensor 的数据类型，numpy 接受 tuple 类型\n",
    "\n",
    "b = b.astype(float)  # torch 与 numpy 转换元素数据类型所使用方法不同，前者使用 astype 方法，后者直接转化\n",
    "# 也可创建的时候直接指定类型 b = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=float)\n",
    "print(b, b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c6971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.] (3,)\n",
      "[[1. 1. 1.]] (1, 3)\n"
     ]
    }
   ],
   "source": [
    "c = np.ones(3)\n",
    "print(c, c.shape)\n",
    "c = np.ones((1, 3))\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577b088f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]] (2, 2, 3)\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]] (3, 4)\n"
     ]
    }
   ],
   "source": [
    "d = [i for i in range(1, 13)]\n",
    "d = np.array(d)\n",
    "\n",
    "d1 = d.reshape((2, 2, -1))\n",
    "print(d1, d1.shape)\n",
    "1\n",
    "d2 =  d.reshape((3, -1))\n",
    "print(d2, d2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df4291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9] (10,)\n",
      "[10 11 12 13 14 15 16 17 18 19] (10,)\n",
      "[10 12 14 16 18 20] (6,)\n"
     ]
    }
   ],
   "source": [
    "e = np.arange(10)\n",
    "print(e, e.shape)\n",
    "\n",
    "e = np.arange(10, 20)\n",
    "print(e, e.shape)\n",
    "\n",
    "e = np.arange(10, 21, 2)\n",
    "print(e, e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55eedeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] (10,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] (10,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] (10,)\n"
     ]
    }
   ],
   "source": [
    "f = np.ones(10)\n",
    "print(f, f.shape)\n",
    "\n",
    "f = np.zeros(10)\n",
    "print(f, f.shape)\n",
    "\n",
    "f = np.empty(10)\n",
    "print(f, f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09eb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.         10.71428571 11.42857143 12.14285714 12.85714286 13.57142857\n",
      " 14.28571429 15.         15.71428571 16.42857143 17.14285714 17.85714286\n",
      " 18.57142857 19.28571429 20.        ] (15,)\n"
     ]
    }
   ],
   "source": [
    "g = np.linspace(10, 20, 15)\n",
    "print(g, g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3aa68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1 2 4]\n",
      " [2 1 5 4]\n",
      " [8 7 9 6]\n",
      " [9 3 4 1]\n",
      " [1 3 8 2]] (5, 4)\n",
      "[[1 1 1 1 2 2 2 3 3 3 4 4 4 5 6 7 8 8 9 9]]\n",
      "[[1 1 2 1]\n",
      " [2 1 4 2]\n",
      " [3 3 5 4]\n",
      " [8 3 8 4]\n",
      " [9 7 9 6]]\n",
      "[[[3 1 2 4 2]\n",
      "  [1 5 4 8 7]]\n",
      "\n",
      " [[9 6 9 3 4]\n",
      "  [1 1 3 8 2]]] (2, 2, 5)\n",
      "[[[1 2 2 3 4]\n",
      "  [1 4 5 7 8]]\n",
      "\n",
      " [[3 4 6 9 9]\n",
      "  [1 1 2 3 8]]] (2, 2, 5)\n"
     ]
    }
   ],
   "source": [
    "h = np.array([[3, 1, 2, 4], [2, 1, 5, 4], [8, 7, 9, 6], [9, 3, 4, 1], [1, 3, 8, 2]])\n",
    "print(h, h.shape)\n",
    "\n",
    "h1 = h.reshape((1, -1)) \n",
    "h1 = np.sort(h1)  # torch 返回值是一个 tuple，(value, indices)，代表排序后的值和排序前的下标\n",
    "print(h1)\n",
    "\n",
    "h2 = h\n",
    "h2 = np.sort(h2, axis=0) # torch 轴参数一般写为 dim，numpy 写为 axis，默认为 -1 按照最后一个维度排序\n",
    "print(h2)\n",
    "\n",
    "h3 = h.reshape((2, 2, -1))\n",
    "print(h3, h3.shape)\n",
    "\n",
    "h4 = h3\n",
    "h4 = np.sort(h4, axis=-1)\n",
    "print(h4, h4.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09244ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 5 6]\n",
      " [3 4 7 8]] (2, 4)\n"
     ]
    }
   ],
   "source": [
    "i = np.array([[1, 2], [3, 4]])\n",
    "j = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "i = np.concatenate((i, j), axis=-1) # torch 轴参数为 dim，numpy 轴参数为 axis，torch 的 cat() 方法与 numpy 的 concatenate() 方法有一样的效果\n",
    "print(i, i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb94cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61.1963156  77.77120822 61.5454976  65.60899095 90.34240107 73.03116735\n",
      " 77.40856847 78.79810204 96.75897514 66.58395263] (10,)\n",
      "[[6 3 9]\n",
      " [1 1 2]\n",
      " [3 5 7]] (3, 3)\n",
      "[[ 0.99626141 -0.47596991 -1.8375531 ]\n",
      " [-0.35660089 -1.35998422  1.3092691 ]] (2, 3)\n",
      "[[-1.73422544 -2.45405005  1.84580967]\n",
      " [ 0.28095907  0.72451289 -0.33716197]] (2, 3)\n"
     ]
    }
   ],
   "source": [
    "# torch 的 randint() 和 normal() 方法都不接受向量类型的参数，也就是一维的 numpy 数组\n",
    "k = 40 * np.random.random(10) + 60 # torch 的 rand() 方法与 numpy 的 random.random() 方法有一样的效果\n",
    "print(k, k.shape)\n",
    "\n",
    "k = np.random.randint(1, 10, (3, 3)) # torch 的 randint() 方法与 numpy 的 random.randint() 方法有一样的效果\n",
    "print(k, k.shape)\n",
    "\n",
    "k = np.random.normal(0, 1, (2, 3)) # torch 的 normal() 方法与 numpy 的 random.normal() 方法有一样的效果\n",
    "print(k, k.shape)\n",
    "\n",
    "k = np.random.randn(2, 3) # torch 的 randn() 方法与 numpy 的 random.randn() 方法有一样的效果\n",
    "print(k, k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c377f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 9] (3,)\n",
      "[[100   1   2   4]\n",
      " [  2 100   5   4]\n",
      " [  8   7 100   6]\n",
      " [  9   3   4   1]\n",
      " [  1   3   8   2]] (5, 4)\n"
     ]
    }
   ],
   "source": [
    "m = np.array([[3, 1, 2, 4], [2, 1, 5, 4], [8, 7, 9, 6], [9, 3, 4, 1], [1, 3, 8, 2]])\n",
    "m1 = m[[0, 1, 2], [0, 1, 2]]\n",
    "print(m1, m1.shape)\n",
    "\n",
    "m[[0, 1, 2], [0, 1, 2]] = 100\n",
    "print(m, m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea2d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10] (10,)\n",
      "[3 4 5 6 7 8] (6,)\n",
      "[1 3 5 7 9] (5,)\n",
      "[2 4 6 8] (4,)\n"
     ]
    }
   ],
   "source": [
    "n = np.arange(1, 11)\n",
    "print(n, n.shape)\n",
    "\n",
    "n1 = n[2:-2]\n",
    "print(n1, n1.shape)\n",
    "\n",
    "n2 = n[::2]\n",
    "print(n2, n2.shape)\n",
    "\n",
    "n3 = n[1:-1:2]\n",
    "print(n3, n3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6afdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3]\n",
      " [7 9]]\n",
      "[7 8 9] [7 8 9]\n",
      "[[3]\n",
      " [6]\n",
      " [9]]\n",
      "[[2 3]\n",
      " [5 6]\n",
      " [8 9]]\n"
     ]
    }
   ],
   "source": [
    "o = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(o[::2, ::2])\n",
    "\n",
    "print(o[2], o[2, :])\n",
    "\n",
    "print(o[:, 2].reshape(1, -1).T) # 直接输出 o[:, 2] 是一个向量不是列矩阵，采用本方法转化，截取列大于 1，就会自动转化为列矩阵，等价于 o[:, 2].reshape(-1, 1)\n",
    "print(o[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8582e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 100   3   4   5   6   7   8   9  10] (10,)\n",
      "[  1 100   3   4   5   6   7   8   9  10] (10,)\n",
      "[1000  100    3    4    5    6    7    8    9   10] (10,)\n",
      "[1000  100    3    4    5    6    7    8    9   10] (10,)\n"
     ]
    }
   ],
   "source": [
    "p = np.arange(1, 11)\n",
    "p1 = p[1:5]\n",
    "p1[0] = 100\n",
    "print(p, p.shape)\n",
    "\n",
    "p2 = p[1:5].copy()  # torch 的 clone() 方法和 numpy 的 copy() 方法有相同的效果\n",
    "p2[0] = 1000\n",
    "print(p, p.shape)\n",
    "\n",
    "p3 = p\n",
    "p3[0] = 1000\n",
    "print(p, p.shape)\n",
    "\n",
    "p4 = p.copy()\n",
    "p4[0] = 10000\n",
    "print(p, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351afafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  9  8  7  6  5  4  3  2  1] (10,)\n"
     ]
    }
   ],
   "source": [
    "q = np.arange(1, 11)\n",
    "q = np.flipud(q)\n",
    "print(q, q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2eeeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 8 9]\n",
      " [4 5 6]\n",
      " [1 2 3]] (3, 3)\n",
      "[[3 2 1]\n",
      " [6 5 4]\n",
      " [9 8 7]] (3, 3)\n"
     ]
    }
   ],
   "source": [
    "r = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "rud = np.flipud(r)\n",
    "rlr = np.fliplr(r)\n",
    "print(rud, rud.shape)\n",
    "print(rlr, rlr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] [3 4 5 6 7 8] [ 9 10]\n",
      "[100   2   3   4   5   6   7   8   9  10]\n",
      "[[100   2   3   4   5]] [[ 6  7  8  9 10]]\n",
      "[[100]\n",
      " [  6]]\n",
      "[[ 2  3  4  5]\n",
      " [ 7  8  9 10]]\n"
     ]
    }
   ],
   "source": [
    "s = np.arange(1, 11)\n",
    "\n",
    "s1, s2, s3 = np.split(s, [2, 8]) # torch 的 split() 方法用起来和 numpy 的完全不一样，前者需要手动的指定块的大小，如果是一个值的话代表等分，后者代表切割的位置\n",
    "# 块的大小的加和要严格的相等，需要手动算一下，不能等于吧最后一个维度留作 -1， 除非等分的时候，最后不足才会自动切割\n",
    "print(s1, s2, s3)\n",
    "s1[0] = 100\n",
    "print(s)\n",
    "\n",
    "s = s.reshape((2, -1))\n",
    "s1, s2 = np.split(s, [1], axis=0)\n",
    "print(s1, s2)\n",
    "\n",
    "s1, s2 = np.split(s, [1], axis=1)\n",
    "print(s1)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1127877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  8 27 64]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "t = np.arange(1, 5)\n",
    "print(t ** 3)\n",
    "\n",
    "t1 = -t\n",
    "print(t)\n",
    "t1[0] = 100\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088af09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]]\n",
      "[0 1 2]\n",
      "[[ 0  1  4  9 16]\n",
      " [ 0  6 14 24 36]\n",
      " [ 0 11 24 39 56]]\n",
      "[[ 0  0  0  0  0]\n",
      " [ 5  6  7  8  9]\n",
      " [20 22 24 26 28]]\n",
      "[[0 0 0 0 0]\n",
      " [0 1 2 3 4]\n",
      " [0 2 4 6 8]]\n"
     ]
    }
   ],
   "source": [
    "u1 = np.arange(0, 5)\n",
    "u2 = np.arange(0, 15).reshape(3, -1)\n",
    "u3 = np.arange(0, 3)\n",
    "\n",
    "print(u1)\n",
    "print(u2)\n",
    "print(u3)\n",
    "# 广播和矩阵乘法没有任何关系，广播成 (x, y) 大小，逐元素相乘而已，左乘本身要是 (1, y)，右乘本身要是 (x, 1)\n",
    "\n",
    "print(u1 * u2)\n",
    "print(u3.reshape(-1, 1) * u2)\n",
    "\n",
    "# 当形状为 (1, y) 和 (x, 1) 相乘，都广播为大小 (x, y) 逐元素相乘\n",
    "\n",
    "print(u1 * u3.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16215bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[ 90 100 110]\n",
      "[[  8   9  10  11  12  13  14  15]\n",
      " [ 24  29  34  39  44  49  54  59]\n",
      " [ 40  49  58  67  76  85  94 103]\n",
      " [ 56  69  82  95 108 121 134 147]\n",
      " [ 72  89 106 123 140 157 174 191]]\n"
     ]
    }
   ],
   "source": [
    "v1 = np.arange(0, 5)\n",
    "v2 = np.arange(0, 5)\n",
    "\n",
    "print(np.dot(v1, v2)) # 矩阵乘法混有向量的时候，根据需求自动的充当行矩阵或者列矩阵，混有向量的时候输出结果一定是向量\n",
    "# torch 使用 dot 的时候，必须保证两个全是向量\n",
    "\n",
    "v3 = np.arange(0, 15).reshape(5, -1)\n",
    "print(np.dot(v1, v3))  # torch 向量乘向量的时候可以使用 dot() 方法，但是只要两者之间出现矩阵，就必须使用 matmul() 方法，当然向量之间的乘法也可以使用 matmul() 方法\n",
    "\n",
    "v4 = np.arange(0, 10).reshape(5, -1)\n",
    "v5 = np.arange(0, 16).reshape(2, -1)\n",
    "\n",
    "print(np.dot(v4, v5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79c587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[ 0.84147098  0.90929743 -0.14112001] [ 0.54030231 -0.41614684 -0.9899925 ] [ 1.55740772 -2.18503986  0.14254654]\n",
      "[ 2.71828183  7.3890561  20.08553692] [2 4 8] [  10  100 1000]\n",
      "[0.         2.30258509 4.60517019 6.90775528] [0.         3.32192809 6.64385619 9.96578428] [0. 1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([1, 2, -3])\n",
    "\n",
    "print(np.abs(w))\n",
    "print(np.sin(w), np.cos(w), np.tan(w))\n",
    "\n",
    "w1 = np.array([1, 2, 3])\n",
    "print(np.exp(w1), 2 ** w1, 10 ** w1) # torch 的 exp() 函数必须传入张量类型 \n",
    "\n",
    "w2 = np.array([1, 10, 100, 1000])\n",
    "print(np.log(w2), np.log(w2) / np.log(2), np.log(w2) / np.log(10))\n",
    "# torch 的 log() 函数必须传入张量类型\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f0d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6] [3 6]\n",
      "[5 7 9] [ 6 15]\n",
      "[ 4 10 18] [  6 120]\n",
      "[2.5 3.5 4.5] [1.5 1.5 1.5]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3], [4, 5, 6]]) \n",
    "\n",
    "print(np.max(x, axis=0), np.max(x, axis=1)) # torch 的 max 函数也会返回最大值和最大值的位置\n",
    "print(np.sum(x, axis=0), np.sum(x, axis=1))\n",
    "print(np.prod(x, axis=0), np.prod(x, axis=1))\n",
    "print(np.mean(x, axis=0), np.std(x, axis=0)) # torch 里面的 mean()、std() 函数只接受浮点类型的数组\n",
    "\n",
    "# nanmax ... 忽略缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c9bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6809\n",
      "[False False  True] True False\n"
     ]
    }
   ],
   "source": [
    "y = np.random.normal(0, 1, (10000, ))\n",
    "\n",
    "print(np.sum(np.abs(y) <= 1))\n",
    "\n",
    "y1 = np.array([1, 2, 3])\n",
    "y2 = np.array([3, 4, 3])\n",
    "print(y1 == y2, np.any(y1 == y2), np.all(y1 == y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df46712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6 7 8 9] (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))\n"
     ]
    }
   ],
   "source": [
    "z = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "z1 = z >= 4\n",
    "print(z[z1], np.where(z1)) # 矩阵进行掩码操作变化为了向量"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
