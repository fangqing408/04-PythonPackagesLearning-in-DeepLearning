{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e81ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: imgs.shape=torch.Size([64, 3, 112, 112]), unique_classes=8\n",
      "tensor([ 8533,  8072,  8072,  8533,  9137,  8072,  8047,  9137,  8047,  8533,\n",
      "         4938,  8533,   297,   297, 10219, 10219, 10219,  8533,   297,  9137,\n",
      "         4938, 10219,  8072,  4938,  8072,  1927, 10219,  8047,  4938,  4938,\n",
      "         8533,   297,  8533,  4938,  9137,  1927,   297,  9137,  8047,  8047,\n",
      "         1927,  1927,  8047,  1927,  8533,   297,  8072,  4938,  1927,  9137,\n",
      "         1927, 10219,  1927,  8072,   297,   297, 10219,  8072,  4938,  8047,\n",
      "         8047,  9137, 10219,  9137])\n",
      "batch 1: imgs.shape=torch.Size([64, 3, 112, 112]), unique_classes=8\n",
      "tensor([ 931, 6165, 7620, 6165,  931,  931, 7620, 7620, 3396, 1070, 1070,  835,\n",
      "        7620, 1070, 7620, 3396, 7620,  835,  931, 3396, 1070, 3396,  835, 5486,\n",
      "        3536,  931, 3536, 3536, 3536, 3536, 6165, 5486,  931, 5486, 7620,  931,\n",
      "        6165, 6165,  835, 5486,  835, 7620,  835, 3536, 3396, 5486, 3396,  931,\n",
      "        6165, 1070, 3396, 5486, 3536, 1070, 3396, 1070, 5486, 6165,  835,  835,\n",
      "        1070, 6165, 5486, 3536])\n",
      "batch 2: imgs.shape=torch.Size([64, 3, 112, 112]), unique_classes=8\n",
      "tensor([ 8320,  9377,  8320,  6075,  6075,  8320,  9629,  1475, 10081, 10081,\n",
      "         8270,  9377,  8320,  9629,  8270,  9629,  9629,  9629, 10081,  2628,\n",
      "         9629,  9629,  8270,  8270,  2628,  2628,  1475,  9377,  2628,  2628,\n",
      "         1475,  6075,  6075,  9377, 10081, 10081,  9377,  8270,  1475,  8320,\n",
      "         8270,  2628,  1475, 10081,  8320,  6075,  8270,  1475,  9377, 10081,\n",
      "         6075,  8320,  1475,  6075,  9377,  2628,  6075,  2628,  1475,  8320,\n",
      "         8270,  9629, 10081,  9377])\n",
      "batch 3: imgs.shape=torch.Size([64, 3, 112, 112]), unique_classes=8\n",
      "tensor([7827, 3445, 3445, 3445, 7859, 1018, 7827, 7552, 7827, 5992, 4397, 7552,\n",
      "        3445, 1018, 7493, 5992, 7552, 7493, 4397, 4397, 7859, 1018, 7493, 1018,\n",
      "        3445, 7827, 7859, 7552, 4397, 5992, 7493, 5992, 4397, 7493, 7827, 7552,\n",
      "        7827, 3445, 7859, 7859, 7827, 7859, 3445, 4397, 5992, 5992, 1018, 7552,\n",
      "        7493, 7859, 1018, 4397, 7552, 5992, 5992, 7493, 7859, 4397, 7827, 1018,\n",
      "        1018, 7552, 7493, 3445])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "from PIL import Image\n",
    "import os, math\n",
    "import random\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class PKDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        classes = sorted(os.listdir(root))\n",
    "        self.num_classes = len(classes)\n",
    "        for label, cls in enumerate(classes):\n",
    "            path = os.path.join(root, cls)\n",
    "            self.class_to_idx[cls] = label\n",
    "            for fname in os.listdir(path):\n",
    "                if fname.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "                    img_path = os.path.join(path, fname)\n",
    "                    self.samples.append((img_path, label))\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "class PKSampler(Sampler):\n",
    "    def __init__(self, data, P=16, K=16, shuffle=True):\n",
    "        self.data = data\n",
    "        self.P = P\n",
    "        self.K = K\n",
    "        self.shuffle = shuffle\n",
    "        self.lab2idx = {}\n",
    "        # 建立 label -> indices 映射\n",
    "        for idx, (_, label) in enumerate(data.samples):\n",
    "            self.lab2idx.setdefault(label, []).append(idx)\n",
    "        self.labels_unique = list(self.lab2idx.keys())\n",
    "        # self.lab2idx\n",
    "        # {\n",
    "        #     0: [0, 5, 12, 27, ...],\n",
    "        #     1: [1, 9, 18, ...],\n",
    "        #     2: [2, 6, 8, ...],\n",
    "        #     ...\n",
    "        # }\n",
    "        # self.labels_unique [0, 1, 2, ...], 随机打乱标签抽取 P 个，每类再取 K 个样本\n",
    "    def __iter__(self):\n",
    "        # 拷贝，避免修改原列表，打乱的话，就在类级别打乱\n",
    "        classes = self.labels_unique.copy()\n",
    "        if self.shuffle:\n",
    "            random.shuffle(classes)\n",
    "        batch = []\n",
    "        # 步长为 P，每次切出 P 个类\n",
    "        for i in range(0, len(classes), self.P):\n",
    "            cls_batch = classes[i:i + self.P]\n",
    "            # 不足 P 个，从所有类里面随机补到 P 个\n",
    "            if len(cls_batch) < self.P:\n",
    "                cls_batch += random.sample(self.labels_unique, self.P - len(cls_batch))\n",
    "            for c in cls_batch:\n",
    "                # 取出这类的所有样本，足够长，无放回随机抽 K 个，不足的话就有放回抽样\n",
    "                idx_pool = self.lab2idx[c]\n",
    "                if len(idx_pool) >= self.K:\n",
    "                    chosen = random.sample(idx_pool, self.K)\n",
    "                else:\n",
    "                    chosen = random.choices(idx_pool, k=self.K)\n",
    "                # 凑好的 batch 返回，再次将 batch 置为空\n",
    "                batch.extend(chosen)\n",
    "            random.shuffle(batch)\n",
    "            yield batch\n",
    "            batch = []\n",
    "\n",
    "    def __len__(self):\n",
    "        # 不是样本数，而是批次数的估计值，最后一个可能因为补类而略有误差，不过对 DataLoader 来说够用了\n",
    "        return math.ceil(len(self.labels_unique) / self.P)\n",
    "    \n",
    "# ======================================================\n",
    "# =============== 验证数据集的创建情况 ==================\n",
    "# ======================================================\n",
    "if __name__ == \"__main__\":\n",
    "    transform = T.Compose([\n",
    "        T.Resize((112, 112)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "    dataset = PKDataset(\"./CASIA-WebFace\", transform=transform)\n",
    "    sampler = PKSampler(dataset, P=8, K=8)\n",
    "    loader = DataLoader(dataset, batch_sampler=sampler, num_workers=0, pin_memory=True)\n",
    "    loader_iter = iter(loader)\n",
    "    for i in range(4):\n",
    "        imgs, labels = next(loader_iter)\n",
    "        print(f\"batch {i}: imgs.shape={imgs.shape}, unique_classes={len(torch.unique(labels))}\")\n",
    "        print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679a7c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: imgs.shape=torch.Size([8, 1, 28, 28]), labels=[1, 7, 6, 5, 4, 4, 3, 8]\n",
      "batch 1: imgs.shape=torch.Size([8, 1, 28, 28]), labels=[4, 4, 3, 8, 7, 9, 5, 1]\n",
      "batch 2: imgs.shape=torch.Size([8, 1, 28, 28]), labels=[7, 9, 5, 1, 8, 9, 7, 7]\n",
      "batch 3: imgs.shape=torch.Size([8, 1, 28, 28]), labels=[8, 9, 7, 7, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "\n",
    "class OverlapDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        classes = sorted(os.listdir(root))\n",
    "        self.num_classes = len(classes)\n",
    "        for label, cls in enumerate(classes):\n",
    "            path = os.path.join(root, cls)\n",
    "            self.class_to_idx[cls] = label\n",
    "            for fname in os.listdir(path):\n",
    "                if fname.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "                    img_path = os.path.join(path, fname)\n",
    "                    self.samples.append((img_path, label))\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"L\")\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "class OverlapSampler(Sampler):\n",
    "    def __init__(self, data, batch_size, overlap_ratio=0.4, shuffle=True):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.overlap_ratio = overlap_ratio\n",
    "        self.step = int(batch_size * (1 - overlap_ratio))\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = [\n",
    "            list(range(i, i + batch_size))\n",
    "            for i in range(0, len(data) - batch_size + 1, self.step)\n",
    "        ]\n",
    "    def __iter__(self):\n",
    "        indices = list(range(len(self.data)))\n",
    "        if self.shuffle: random.shuffle(indices)\n",
    "        for i in range(0, len(self.data) - self.batch_size + 1, self.step):\n",
    "            batch_idxs = indices[i:i + self.batch_size]\n",
    "            yield batch_idxs\n",
    "    def __len__(self):\n",
    "        return (len(self.data) - self.batch_size) // self.step + 1\n",
    "\n",
    "# ======================================================\n",
    "# ===============验证数据集的创建情况====================\n",
    "# ======================================================\n",
    "if __name__ == \"__main__\":\n",
    "    transform = T.Compose([\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "    dataset = OverlapDataset(\"./mnist_test_torch\", transform=transform)\n",
    "    sampler = OverlapSampler(dataset, batch_size=8, overlap_ratio=0.4)\n",
    "    loader = DataLoader(dataset, batch_sampler=sampler, num_workers=0, pin_memory=True)\n",
    "    # DataLoader 的底层逻辑的先看你有没有提供自己的 Sampler，否则的话自己创建随机的采样，当循环遍历 loader 的时候，这个迭代器会不断的调用 indices=next(iter(sampler))\n",
    "    # 和 Dataset 类似，sampler 必须实现两个函数 __iter__ 和 __len__，__iter__ 返回的一堆索引，也就是 DataLoader 加载数据的索引\n",
    "    loader_iter = iter(loader)\n",
    "    for i in range(4):  # 取前4个batch\n",
    "        imgs, labels = next(loader_iter)\n",
    "        print(f\"batch {i}: imgs.shape={imgs.shape}, labels={labels.tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "202510-learning (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
